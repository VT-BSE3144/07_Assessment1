---
title: "BSE3144 - Assessment 1"
author: "your name here"
date: "2024-03-15"
output:
  pdf_document:
    df_print: tibble
  word_document: default
geometry: margin=1.25in
fontsize: 14
font-family: Garamond
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = 'formatR' )
library(tidyverse)
library(datasets)
```
```{r points, include=FALSE}
# Calculating point totals
assessment <- read_file("Assessment1.Rmd") %>%
  str_extract_all("\\+\\d", simplify = TRUE) %>% 
  str_remove("\\+") %>% as.numeric()
sum(assessment)
```
```{text Rubric, include=FALSE}
# Rubric/Grading

This project-based assessment contains `r length(assessment)` questions or tasks, with point values varying from `r min(assessment)` to `r max(assessment)`, corresponding to how much effort we expect you to put into each questions or task. Altogether this assessment is worth `r sum(assessment)` points, for reference. So a `r sum(assessment)/10` point question/task should take ~1/10th of the total time you spend on this project. You will have 1 whole week in class to finish this project (and the week of spring break to polish it, if you want). We fully expect you to be able to finish this project in the 2 class hours plus 4-6 hours you should spend outside of class working through materials in a typical week. So that `r sum(assessment)/10` point question/task should take ~30-45 minutes to complete, not including troubleshooting errors. Everyone works at different paces and has different innate abilities, but if you appear to have put much less effort than expected into a question task you will receive less than the full allotted points. If you have gone above and beyond the requirements of the question/task you may receive more than the allotted points.

Within the document below you will find point totals for each task/question marked with a "+", and the number of points. 

```
```{text Directions, include=FALSE}
# Directions

In this assessment we are asking you to choose or identify a data set you are interested in and demonstrate your skills of data wrangling and visualization through asking questions about the data set. 

**This assessment is individual. Everyone must submit a unique document.** However you may work with a partner on the same dataset to allow you to bounce ideas off of each other and discuss your questions and plans to answer them. In general you can feel free to talk to any of your colleagues about what you are working on, as this is known to increase creativity, engagement, and enjoyment, but **everyone must submit an _individual, unique_ document.** 

## Finding a data set 

Data is everywhere these days. Below we have some recommendations about where to find datasets to use for this assessment, but there are many more options out there, from different governmental agencies, to research papers, to data repositories. Google a topic you are interested in plus "data" and see what you can find, or check out the resources below. 

The critical things a dataset must have for this assessment are:

- ability to be downloaded (as a csv/tsv/excel/sas/stata/spss file ideally)
- at least 1 numerical variable
- at least 1 categorical variable
- something that you care about, so you are willing to put some time into this assessment

### Health

https://www.who.int/data - The World Health organization has lots of very interesting datasets that are pretty accessible. We would recommend in particular, [Child mortality and causes of death](https://www.who.int/data/gho/data/themes/topics/topic-details/GHO/child-mortality-and-causes-of-death) and [Life expectancy data by country](https://www.who.int/data/gho/data/themes/mortality-and-global-health-estimates/ghe-life-expectancy-and-healthy-life-expectancy).

https://healthdata.gov/ - This site is dedicated to making high value health data more accessible to entrepreneurs, researchers, and policy makers in the hopes of better health outcomes.

https://www.nyam.org/library/collections-and-resources/data-sets/ - The New York Academy of Medicine has links to many publicly available, medical data sets. 

https://www.cdc.gov/datastatistics/index.html - CDC has many datasets, some may be difficult to access or read into R, as they often have their own data visualization tools, but with some digging you can find the raw datasets.

### Environment

https://waterdata.usgs.gov/nwis - These pages provide access to water-resources data collected at approximately 1.9 million sites across the US and its territories.

https://data.noaa.gov/datasetsearch/ - NOAA has many datasets related to the environment from weather and water, to ecology and environmental health. These are generally pretty accessible too.

### Agriculture

https://data.nal.usda.gov/ - The USDA has a large collection of agriculturally relevant data sets.

### General 

https://data.world/datasets - data.world has thousands of data sets on all kinds of different topics that are all open and freely available, but you have to make an account.  

https://datadryad.org/stash - This site is a repository for all kinds of research data, use the search tool to find something you are interested in.

https://udc.vt.edu/ - Virginia Tech's University data commons has all kinds of data about our campus community over time that can be visualized in different ways and downloaded as CSVs. 

https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/00Index.html - The R datasets package has lots of different data sets on a wide variety of topics

https://www.vdh.virginia.gov/data/ - Virginia Department of Health has lots of datasets, mostly health related but also some environmental datasets. 


## Questions/Tasks

Any text that is flanked by two asterisk's `**` (which causes text to appear in bold face in the "Visual" version of the document) is a prompt for you to answer or fill in details below. Outside of code chunks, this text will appear as bold. We have still added the `**` inside of comments in code chunks so you will know where you need to fill in. 

## Guideline on the Use of AI Tools

In this assignment, you are welcome to use AI tools (such as ChatGPT, Claude, Copilot, automated data cleaning packages, etc) to support your brainstorming, code generation, data wrangling, or visualization tasks. However, it is essential that you use these tools critically and responsibly. Specifically consider:

**Verification and Validation:** Always verify and validate any output generated by AI tools. Ensure that the code and analysis you submit is accurate, reproducible, and truly reflects your own understanding.

**Documentation:** Clearly document any instance where AI tools were used. Describe the process, the suggestions provided by the AI, and any modifications you made to tailor the output to your projectâ€™s needs.

**Ethical Considerations:** Reflect on and acknowledge the benefits and limitations of using AI. Consider issues such as potential biases in AI-generated outputs, the transparency of the process, and the ethical implications of relying on automated tools in data analysis.

By adhering to these guidelines, you will demonstrate both technical proficiency and a critical, ethical approach to the integration of AI in your data analysis process.

```

# Introduction

**Provide a brief description of your data set and why it was collected or is of interest to you. Why should we (and anyone else) be excited about your project?**


+4

## Data source(s)

**Where did you obtain your data set? (Provide a web address and description of how you obtained your data).** 


+1

**Was your dataset and/or the conclusions from it published anywhere on the web or in a peer-reviewed scientific journal?**


+1

**Does your dataset have a good README file or Data Dictionary? Are there any missing pieces of information about variables or how the data was collected?** 


+2

**Is your data set "tidy" in its original form? Why or why not?**


+2

```{r}
# **Tidy your data here if necessary, or check that it is tidy, 
# following the guidelines from Week 1**


# +1
```


```{r}
# **Write code below to view the first 6 rows of your chosen tidied data set**


#+1 
```

**Describe the dataset. How was it collected? What are the primary variables? What are the types of the variables (in terms of R object classes)?**


+2

## Questions you could ask and answer using this data

**What are 3 possible questions you could ask, _with your current skills from this class_, about/with this data?**

1.  
2. 
3. 

+2
+2
+2

# Data Wrangling

**In this section we want you to demonstrate your ability to wrangle data using functions from the dplyr and tidyr packages. Towards answering the questions you pose above, complete the following:**

## Convert a numerical variable from one unit to another, or create a new variable to help you answer one of your questions

**Describe your reasoning behind creating this new variable.**


+2

```{r}
# **Replace this with code to do a unit conversion or create a new variable**


# +2
```

## Create a summary table that will help you answer one of your questions above

**Describe the summary table you plan to make and why.**


+2

```{r}
# **Replace this with code to create a summary table**


# +2
```

**Describe your conclusions from this summary table in relation to your question above.**


+2 

# Plotting

**Which of your questions above, might best be answered with a plot? Describe the plot you would make to begin answering this question and why this plot would be best for answering this question.**


+3

**Make the plot you describe above. Include all additional data wrangling required to make the plot**

```{r}
# **Write code here to create your plot**


# +3
```

**Based on the above plot, how would you answer the question you posed above?**


+3

**What improvements/changes could you make to this plot or the data set to improve your answer or confidence in your answer?**


+2

# Critical Evaluation of AI-use in Data Analysis

**Reflect on the role (real or potential) of AI in your (current or future) data analysis process. Did you use any AI tools (e.g., ChatGPT, Claude, Copilot, automated data cleaning packages, etc.) to assist in brainstorming, code generation, data wrangling, or visualization? If you used these tools,  briefly describe how you used these tools and provide a critical evaluation of the results. What steps did or would you take to verify or validate the output provided by the AI? Discuss the potential benefits, limitations, and ethical considerations of using AI in this context.**


+4
